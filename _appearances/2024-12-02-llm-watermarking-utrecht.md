---
layout: appearance
title: "Learnable Fingerprints for Large Language Models"
date: 2024-12-02 19:00:00
description: "A talk about watermarking LLM outputs to distinguish AI-generated from human-written content, discussing methods to maintain trust in digital content creation."
organization: "Incognito - Utrecht University's AI Study Association"
location: "Mick O'Connels, Utrecht, Netherlands"
tags:
  - AI Safety
  - LLM
  - Watermarking
  - Research
---

# Caf√©-KI: Learnable Fingerprints for Large Language Models

Large Language Models (LLMs) have become ubiquitous in content creation, raising important questions about trust and authenticity in digital content. As more text is generated by AI rather than written by humans, there's a growing need to distinguish between the two sources.

In this talk, I discussed my research on watermarking LLM outputs - a technical approach to embedding traceable signatures in AI-generated content. We explored:

- The importance of maintaining trust in digital content
- Technical approaches to watermarking LLM outputs
- Challenges and considerations in implementation
- Future implications for content authenticity